{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "soo5pTQQUNsK"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Initialization"
      ],
      "metadata": {
        "id": "xGeZGNCtUOLT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gymnasium"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blvr4AJJ-VfQ",
        "outputId": "aa30be35-e377-4c56-885b-49dffb94acf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gymnasium\n",
            "  Downloading gymnasium-0.29.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (1.26.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (4.12.2)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium)\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n",
            "Downloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Installing collected packages: farama-notifications, gymnasium\n",
            "Successfully installed farama-notifications-0.0.4 gymnasium-0.29.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ONROcIf8V79"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "env = gym.make('CartPole-v1')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Previous tries"
      ],
      "metadata": {
        "id": "soo5pTQQUNsK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "observation, info = env.reset()\n",
        "\n",
        "n_fallen = 0\n",
        "for _ in range(1000):\n",
        "  # Choose an action\n",
        "\n",
        "  # polynomial regression pytorch\n",
        "\n",
        "\n",
        "  # angle -> direction\n",
        "  # if observation[2] < 0:\n",
        "  #   action = 0\n",
        "  # else:\n",
        "  #   action = 1\n",
        "\n",
        "  # random choice\n",
        "  action = env.action_space.sample()  # agent policy that uses the observation and info\n",
        "\n",
        "  observation, reward, terminated, truncated, info = env.step(action)\n",
        "\n",
        "  if terminated or truncated:\n",
        "    observation, info = env.reset()\n",
        "    n_fallen += 1\n",
        "\n",
        "env.close()\n",
        "\n",
        "print(n_fallen)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vZFEPUN-Qy3",
        "outputId": "d33da8ac-8ca7-43bc-dd52-3525d9a3c2dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "\n",
        "# Build the model:\n",
        "class PolynomialRegressionModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.p1 = nn.Parameter(torch.rand( 1,\n",
        "                                                requires_grad=True,\n",
        "                                                dtype=torch.float32))\n",
        "        self.p2 = nn.Parameter(torch.rand( 1,\n",
        "                                                requires_grad=True,\n",
        "                                                dtype=torch.float32))\n",
        "        self.p3 = nn.Parameter(torch.rand( 1,\n",
        "                                                requires_grad=True,\n",
        "                                                dtype=torch.float32))\n",
        "        self.p4 = nn.Parameter(torch.rand( 1,\n",
        "                                                requires_grad=True,\n",
        "                                                dtype=torch.float32))\n",
        "        self.p5 = nn.Parameter(torch.rand( 1,\n",
        "                                                requires_grad=True,\n",
        "                                                dtype=torch.float32))\n",
        "        self.p6 = nn.Parameter(torch.rand( 1,\n",
        "                                                requires_grad=True,\n",
        "                                                dtype=torch.float32))\n",
        "        self.p7 = nn.Parameter(torch.rand( 1,\n",
        "                                                requires_grad=True,\n",
        "                                                dtype=torch.float32))\n",
        "        self.fc1 = nn.Linear(4, 2)\n",
        "\n",
        "        self.softmax = nn.Softmax()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.p1*x**6 + self.p2*x**5 + self.p3*x**4 + self.p4*x**3 + self.p5*x**2 + self.p6*x + self.p7\n",
        "        x = self.fc1(x)\n",
        "        x = self.softmax(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "FlVG1KiBQA4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "observation, info = env.reset()\n",
        "\n",
        "# Create the model\n",
        "torch.manual_seed(42)\n",
        "model = PolynomialRegressionModel()\n",
        "\n",
        "# Define the loss function and the optimizer\n",
        "loss_fn = nn.MSELoss()\n",
        "learning_rate = 0.001\n",
        "optimizer = torch.optim.SGD(params = model.parameters(),\n",
        "                            lr = learning_rate)\n",
        "model.train()\n",
        "\n",
        "for _ in range(1000):\n",
        "  # Choose an action\n",
        "  # polynomial regression pytorch\n",
        "  y_pred = model(torch.from_numpy(observation))\n",
        "  action = env.action_space.sample()\n",
        "\n",
        "  # Loss calculation\n",
        "  good = True if observation[2] > -0.2 and observation[2] < 0.2 else False\n",
        "  y_true = np.array([0, 0], dtype='float32')\n",
        "  y_true[torch.argmax(y_pred) if good else 1 ^ torch.argmax(y_pred)] = 1\n",
        "  y_true = torch.from_numpy(y_true)\n",
        "  loss = loss_fn(y_pred, y_true)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  observation, reward, terminated, truncated, info = env.step(action)\n",
        "\n",
        "  if terminated or truncated:\n",
        "    observation, info = env.reset()\n",
        "\n",
        "# AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\n",
        "\n",
        "n_fallen = 0\n",
        "for _ in range(1000):\n",
        "  # Choose an action\n",
        "  # polynomial regression pytorch\n",
        "  y_pred = model(torch.from_numpy(observation))\n",
        "  action = torch.argmax(y_pred).item()\n",
        "\n",
        "  # Loss calculation\n",
        "  good = True if observation[2] > -0.2 and observation[2] < 0.2 else False\n",
        "  y_true = np.array([0, 0], dtype='float32')\n",
        "  y_true[torch.argmax(y_pred) if good else 1 ^ torch.argmax(y_pred)] = 1\n",
        "  y_true = torch.from_numpy(y_true)\n",
        "  loss = loss_fn(y_pred, y_true)\n",
        "\n",
        "  observation, reward, terminated, truncated, info = env.step(action)\n",
        "\n",
        "  if terminated or truncated:\n",
        "    observation, info = env.reset()\n",
        "    n_fallen += 1\n",
        "\n",
        "env.close()\n",
        "\n",
        "print(n_fallen)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCj6fCqdQv6b",
        "outputId": "26564783-fdff-4ec4-9313-9fcd63fc089b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "101\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "model = PolynomialRegressionModel()\n",
        "model(torch.from_numpy(observation))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vaEr-HzeXFbN",
        "outputId": "7d11a931-8180-41a5-bd4a-543500809a01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1532: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.3886, 0.6114], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(observation)\n",
        "print(observation**2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_G09OxSdap2y",
        "outputId": "41f7f958-e1ba-47aa-9dec-ad776cc7e642"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.00374048  0.22145137  0.01048327 -0.27827266]\n",
            "[1.3991186e-05 4.9040709e-02 1.0989888e-04 7.7435672e-02]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Deep Q-Learning"
      ],
      "metadata": {
        "id": "AersSxRkUXL0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import copy\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "ILPXGHqbXcEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleLinear(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(5, 128)\n",
        "        self.fc2 = nn.Linear(128, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        return x"
      ],
      "metadata": {
        "id": "nB2kYZ6ncJB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tensor_cat(a_np, b_int):\n",
        "  return torch.concatenate((torch.from_numpy(a_np), torch.tensor([b_int])))"
      ],
      "metadata": {
        "id": "tCja1_Ebj7Z6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training"
      ],
      "metadata": {
        "id": "F7ofzRlKpzwl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_iterations = 1000\n",
        "replay_buffer = []\n",
        "p_random_choice = 0.2 # probability to do exploration\n",
        "model = SimpleLinear()\n",
        "prev_model = copy.deepcopy(model)\n",
        "optimizer = torch.optim.SGD(params = model.parameters(), lr = 0.001)\n",
        "num_minibatch = 50\n",
        "future_importance = 1 # TODO: NOT SURE WHAT VALUE THIS CONSTANT SHOULD HAVE\n",
        "model_update_steps = 50 # TODO: NOT SURE WHAT VALUE THIS CONSTANT SHOULD HAVE\n",
        "\n",
        "observation, info = env.reset()\n",
        "\n",
        "with torch.no_grad():\n",
        "  for iteration in tqdm(range(num_iterations)):\n",
        "    # Sampling phase\n",
        "    if np.random.rand() < p_random_choice:\n",
        "      action = env.action_space.sample()\n",
        "    else:\n",
        "      action = np.argmax([model(tensor_cat(observation, action_variant)) for action_variant in [0, 1]])\n",
        "    prev_observation = observation\n",
        "    observation, reward, terminated, truncated, info = env.step(action)\n",
        "    replay_buffer.append((prev_observation, action, reward, observation, terminated or truncated))\n",
        "\n",
        "    # Training phase\n",
        "    if len(replay_buffer) < num_minibatch:\n",
        "      continue\n",
        "\n",
        "    replay_indices = np.random.choice(len(replay_buffer), min(num_minibatch, len(replay_buffer)))\n",
        "    for i_replay in replay_indices:\n",
        "      sample = replay_buffer[i_replay]\n",
        "      if sample[4]: # If last transition\n",
        "        y_true = sample[2]\n",
        "      else:\n",
        "        # The error was here.\n",
        "        # I calculated q_value_true using initial observation from sample,\n",
        "        # but it should have been the next observation, so it will connect future rewards\n",
        "        # and proagate them back to this state from the very end.\n",
        "        q_value_true = max([prev_model(tensor_cat(sample[3], action_variant)) for action_variant in [0, 1]])\n",
        "        y_true = sample[2] + future_importance * q_value_true\n",
        "      # Gradient descent step\n",
        "      with torch.enable_grad():\n",
        "        loss = (y_true - model(tensor_cat(sample[0], sample[1]))) ** 2\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    if iteration % model_update_steps == model_update_steps - 1:\n",
        "      prev_model = copy.deepcopy(model)\n",
        "\n",
        "    # Reset\n",
        "    if terminated or truncated:\n",
        "      observation, info = env.reset()\n",
        "\n",
        "env.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6QDwTPIUY3w",
        "outputId": "bd5ff830-7c68-440b-9efa-c4d6fe13789e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:44<00:00, 22.41it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Testing in 1000 interations"
      ],
      "metadata": {
        "id": "-Zj4KgRWpwEM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "observation, info = env.reset()\n",
        "\n",
        "n_fallen = 0\n",
        "with torch.no_grad():\n",
        "  for iteration in tqdm(range(1000)):\n",
        "    action = np.argmax([model(tensor_cat(observation, action_variant)) for action_variant in [0, 1]])\n",
        "    observation, reward, terminated, truncated, info = env.step(action)\n",
        "\n",
        "    if terminated or truncated:\n",
        "      observation, info = env.reset()\n",
        "      n_fallen += 1\n",
        "\n",
        "env.close()\n",
        "\n",
        "print()\n",
        "print(n_fallen)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s98P7mmkhRS4",
        "outputId": "d146332b-4230-4fe8-83c7-63530abddbf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:00<00:00, 1561.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Results"
      ],
      "metadata": {
        "id": "1pqBwZa3UV1-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Results\n",
        "\n",
        "| Method | Number of falls |\n",
        "| --- | --- |\n",
        "| max falls | ~114 |\n",
        "| random choice | ~45 |\n",
        "| angle → direction | ~24 |\n",
        "| polynomial regression v1 | ~100 |\n",
        "| deep q-learning (2 improvements) | 6 |\n",
        "\n",
        "WHYYYYYYYYYYYYYYYYYYYYYYYYYYYYYY CAN'T I JUST WRITE A NORMAL LEARNING ALGORITHM  \n",
        "polynomial regression v1: by state observation it predicts action  \n",
        "deep q-learning (2 improvements): sample deep learning algorithm, https://huggingface.co/learn/deep-rl-course/unit3/deep-q-algorithm"
      ],
      "metadata": {
        "id": "qI6i7oxTBY2h"
      }
    }
  ]
}